# -*- coding: utf-8 -*-
"""LawGPT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UEX4JMW6O8kriDmJWAutNvTSHTLnoGqb
"""

!pip install -q transformers datasets gradio kaggle sentence-transformers faiss-cpu

from google.colab import files
files.upload()  # Upload kaggle.json

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/kaggle.json
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d anishparkhe0401/indian-laws
!unzip -q indian-laws.zip -d indian_laws

!kaggle datasets download -d omdabral/indian-penal-code-complete-dataset
!unzip -q indian-penal-code-complete-dataset.zip -d ipc_data

import os
import json
import pandas as pd
from sentence_transformers import SentenceTransformer, util
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline
import gradio as gr

# Load law sections
with open("/content/indian_laws/combined.json", "r") as f:
    law_data = json.load(f)

# Load IPC dataset
ipc_df = pd.read_csv("/content/ipc_data/FIR_DATASET.csv").dropna()

embedder = SentenceTransformer('all-MiniLM-L6-v2')

# Combine all context texts (law sections + IPC descriptions)
law_texts = [entry["description"] for entry in law_data]
ipc_texts = ipc_df['Description'].tolist()
all_contexts = law_texts + ipc_texts

# Embed all contexts
context_embeddings = embedder.encode(all_contexts, convert_to_tensor=True)

model = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-base")
tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-base")

qa_pipeline = pipeline("text2text-generation", model=model, tokenizer=tokenizer)

def find_semantic_context(question):
    question_embedding = embedder.encode(question, convert_to_tensor=True)
    hits = util.semantic_search(question_embedding, context_embeddings, top_k=1)
    best_index = hits[0][0]['corpus_id']
    return all_contexts[best_index]

def ask_law_bot(question):
    context = find_semantic_context(question)
    prompt = f"Question: {question}\nContext: {context}\nAnswer:"
    result = qa_pipeline(prompt, max_length=256)[0]["generated_text"]
    return result

gr.Interface(
    fn=ask_law_bot,
    inputs="text",
    outputs="text",
    title="⚖️ Indian Legal Chatbot (RAG + Generative)",
    description="Ask questions about IPC or Indian law acts. Powered by semantic search and FLAN-T5."
).launch()